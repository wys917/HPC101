#!/bin/bash
#SBATCH --job-name=qwen3_analysis
#SBATCH --partition=V100
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --gres=gpu:1
#SBATCH --mem=32G
#SBATCH --time=00:15:00
#SBATCH --output=qwen3_analysis_%j.log
#SBATCH --error=qwen3_analysis_%j.err

echo "ğŸš€ å¼€å§‹Qwen3æ¨¡å‹å‚æ•°é‡å’Œæ˜¾å­˜åˆ†æ"
echo "ä½œä¸šID: $SLURM_JOB_ID"
echo "èŠ‚ç‚¹: $SLURM_JOB_NODELIST"
echo "æ—¶é—´: $(date)"
echo "================================"

# æ¿€æ´»ç¯å¢ƒ
source /river/hpc101/2025/lab5/env/bin/activate
source /home/hpc101/h3240103466/miniconda3/etc/profile.d/conda.sh
conda activate myenv

# æ˜¾ç¤ºGPUä¿¡æ¯
echo "GPUä¿¡æ¯:"
nvidia-smi
echo "================================"

# è¿è¡Œå‚æ•°é‡åˆ†æ
echo "è¿è¡Œå‚æ•°é‡å’Œæ˜¾å­˜åˆ†æ..."
cd /home/hpc101/h3240103466/HPC101/src/lab5
python calculate_params.py

echo "================================"
echo "åˆ†æå®Œæˆï¼Œæ—¶é—´: $(date)"

echo "å¼€å§‹åˆ†æQwen3æ¨¡å‹å‚æ•°é‡å’Œæ˜¾å­˜å ç”¨..."
echo "æ—¶é—´: $(date)"
echo "èŠ‚ç‚¹: $SLURM_NODELIST"
echo "GPU: $CUDA_VISIBLE_DEVICES"

# æ¿€æ´»ç¯å¢ƒ
module load anaconda3
source activate /share/anaconda3/envs/llm

echo "Pythonç¯å¢ƒä¿¡æ¯:"
python --version
echo "PyTorchç‰ˆæœ¬: $(python -c 'import torch; print(torch.__version__)')"
echo "CUDAå¯ç”¨: $(python -c 'import torch; print(torch.cuda.is_available())')"

echo ""
echo "å¼€å§‹æ˜¾å­˜åŸºçº¿æµ‹é‡..."
nvidia-smi

echo ""
echo "è¿è¡Œæ¨¡å‹åˆ†æè„šæœ¬..."
python calculate_model_size.py

echo ""
echo "åˆ†æå®Œæˆ!"
echo "ç»“æŸæ—¶é—´: $(date)"
